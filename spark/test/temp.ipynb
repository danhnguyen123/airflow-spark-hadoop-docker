{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/opt/workspace/modules'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/09/03 08:24:09 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.\\\n",
    "        builder.\\\n",
    "        appName(\"pyspark-notebook\").\\\n",
    "        master(\"spark://spark-master:7077\").\\\n",
    "        config(\"spark.executor.memory\", \"512m\").\\\n",
    "        config(\"spark.eventLog.enabled\", \"true\").\\\n",
    "        config(\"spark.eventLog.dir\", \"hdfs://namenode/shared/spark-logs\").\\\n",
    "        config(\"spark.history.fs.logDirectory\", \"hdfs://namenode/shared/spark-logs\").\\\n",
    "        getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/opt/workspace/data/temp.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>phone_number</th>\n",
       "      <th>account_number</th>\n",
       "      <th>campagin</th>\n",
       "      <th>payment_method</th>\n",
       "      <th>success_ekyc</th>\n",
       "      <th>pro_purchase</th>\n",
       "      <th>accountName</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>060a8e05-2ff3-4c9e-bf84-3c21d349531e</td>\n",
       "      <td>947845900</td>\n",
       "      <td>2.637041e+14</td>\n",
       "      <td>1. Existing HDB acc</td>\n",
       "      <td>in-app banking</td>\n",
       "      <td>2022-06-13</td>\n",
       "      <td>2022-09-08</td>\n",
       "      <td>LE HONG NGOC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>108882e7-7fc8-459f-ab04-1272736cd15f</td>\n",
       "      <td>888235816</td>\n",
       "      <td>6.870407e+13</td>\n",
       "      <td>1. Existing HDB acc</td>\n",
       "      <td>in-app banking</td>\n",
       "      <td>2022-08-26</td>\n",
       "      <td>2022-09-08</td>\n",
       "      <td>LE MY HANH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12233148-c010-4e4f-a99f-69204a0a9b83</td>\n",
       "      <td>987722954</td>\n",
       "      <td>6.870407e+13</td>\n",
       "      <td>1. Existing HDB acc</td>\n",
       "      <td>in-app banking</td>\n",
       "      <td>2022-06-14</td>\n",
       "      <td>2022-09-10</td>\n",
       "      <td>BUI VAN GIANG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1e6acde9-5d69-42c1-b538-37f49ffd094a</td>\n",
       "      <td>374351851</td>\n",
       "      <td>9.999904e+14</td>\n",
       "      <td>1. Existing HDB acc</td>\n",
       "      <td>pro_renew</td>\n",
       "      <td>2022-08-09</td>\n",
       "      <td>2022-09-08</td>\n",
       "      <td>HOANG VAN THIEN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20ddfb21-1665-4fc9-9a30-db6c1c3c9dfb</td>\n",
       "      <td>868077077</td>\n",
       "      <td>1.117041e+14</td>\n",
       "      <td>1. Existing HDB acc</td>\n",
       "      <td>in-app banking</td>\n",
       "      <td>2022-08-20</td>\n",
       "      <td>2022-09-10</td>\n",
       "      <td>BUI HONG QUANG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4668a071-f22e-41dd-82ca-af5ecf493652</td>\n",
       "      <td>919238636</td>\n",
       "      <td>8.270407e+13</td>\n",
       "      <td>1. Existing HDB acc</td>\n",
       "      <td>in-app banking</td>\n",
       "      <td>2022-07-13</td>\n",
       "      <td>2022-09-08</td>\n",
       "      <td>LUU PHUC THANH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5a6132ee-acc8-4698-ac2d-d8ceb4e59ab4</td>\n",
       "      <td>917220226</td>\n",
       "      <td>1.237041e+14</td>\n",
       "      <td>1. Existing HDB acc</td>\n",
       "      <td>in-app banking</td>\n",
       "      <td>2022-06-24</td>\n",
       "      <td>2022-09-08</td>\n",
       "      <td>TO THUY OANH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5a9b0c42-2d97-43f3-b0ac-46def015756a</td>\n",
       "      <td>947128158</td>\n",
       "      <td>6.870407e+13</td>\n",
       "      <td>1. Existing HDB acc</td>\n",
       "      <td>in-app banking</td>\n",
       "      <td>2022-08-04</td>\n",
       "      <td>2022-09-08</td>\n",
       "      <td>LE DUY PHUONG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5b66d9c7-6bc6-4a31-9bac-5f19df99ccf0</td>\n",
       "      <td>983215799</td>\n",
       "      <td>6.870407e+13</td>\n",
       "      <td>1. Existing HDB acc</td>\n",
       "      <td>in-app banking</td>\n",
       "      <td>2022-09-07</td>\n",
       "      <td>2022-09-08</td>\n",
       "      <td>PHAN VAN VIET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>8cc45d67-6405-458d-8b86-76834f9fdb64</td>\n",
       "      <td>909733028</td>\n",
       "      <td>8.970407e+13</td>\n",
       "      <td>1. Existing HDB acc</td>\n",
       "      <td>in-app banking</td>\n",
       "      <td>2022-06-28</td>\n",
       "      <td>2022-09-10</td>\n",
       "      <td>DAO XUAN TRUC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>b056bc52-3719-40ec-bf0e-9127fb76bb70</td>\n",
       "      <td>932080184</td>\n",
       "      <td>8.970407e+13</td>\n",
       "      <td>1. Existing HDB acc</td>\n",
       "      <td>in-app banking</td>\n",
       "      <td>2022-07-01</td>\n",
       "      <td>2022-09-09</td>\n",
       "      <td>VU THI THUY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>bd6c3d13-f5fb-4f38-a770-8090d54f8e84</td>\n",
       "      <td>938638169</td>\n",
       "      <td>1.470407e+13</td>\n",
       "      <td>1. Existing HDB acc</td>\n",
       "      <td>cash</td>\n",
       "      <td>2022-04-29</td>\n",
       "      <td>2022-09-08</td>\n",
       "      <td>TRAN THI HONG DIEU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>cc2febc2-7be7-4151-9834-8d478411bf65</td>\n",
       "      <td>355097069</td>\n",
       "      <td>2.287041e+14</td>\n",
       "      <td>1. Existing HDB acc</td>\n",
       "      <td>in-app banking</td>\n",
       "      <td>2022-08-17</td>\n",
       "      <td>2022-09-09</td>\n",
       "      <td>DINH VAN NHO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>d0eb4b72-657b-48ba-91cc-52855febe7bf</td>\n",
       "      <td>876667373</td>\n",
       "      <td>6.870407e+13</td>\n",
       "      <td>1. Existing HDB acc</td>\n",
       "      <td>in-app banking</td>\n",
       "      <td>2022-08-16</td>\n",
       "      <td>2022-09-10</td>\n",
       "      <td>VO AN H KHOA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>ed0cbf71-1f1e-4706-b011-441c3df0de2e</td>\n",
       "      <td>345280737</td>\n",
       "      <td>1.047041e+14</td>\n",
       "      <td>1. Existing HDB acc</td>\n",
       "      <td>in-app banking</td>\n",
       "      <td>2022-07-06</td>\n",
       "      <td>2022-09-08</td>\n",
       "      <td>NGUYEN VAN TOAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1dcc548b-a33d-43dd-9e1f-55f189ceec34</td>\n",
       "      <td>963099780</td>\n",
       "      <td>6.870407e+13</td>\n",
       "      <td>2. New HDB acc</td>\n",
       "      <td>in-app banking</td>\n",
       "      <td>2022-09-09</td>\n",
       "      <td>2022-09-09</td>\n",
       "      <td>DINH THI LUYEN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>289bf7c8-42f0-4d9c-9268-ad323fa2a52e</td>\n",
       "      <td>904020583</td>\n",
       "      <td>6.870407e+13</td>\n",
       "      <td>2. New HDB acc</td>\n",
       "      <td>in-app banking</td>\n",
       "      <td>2022-09-08</td>\n",
       "      <td>2022-09-09</td>\n",
       "      <td>LUONG THI ANH TUYET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>7ce9ee07-b59b-47bd-b476-250ade393703</td>\n",
       "      <td>392219121</td>\n",
       "      <td>6.870407e+13</td>\n",
       "      <td>2. New HDB acc</td>\n",
       "      <td>in-app banking</td>\n",
       "      <td>2022-09-09</td>\n",
       "      <td>2022-09-09</td>\n",
       "      <td>NGUYEN THIEN AN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>a998cc49-3224-4be8-89eb-df0d498f3767</td>\n",
       "      <td>974286156</td>\n",
       "      <td>9.999910e+14</td>\n",
       "      <td>2. New HDB acc</td>\n",
       "      <td>in-app banking</td>\n",
       "      <td>2022-09-09</td>\n",
       "      <td>2022-09-09</td>\n",
       "      <td>NGUYEN VAN TUNG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>b1fe84ee-c73d-4a17-9d60-3ab99a07479c</td>\n",
       "      <td>334074063</td>\n",
       "      <td>6.870407e+13</td>\n",
       "      <td>2. New HDB acc</td>\n",
       "      <td>in-app banking</td>\n",
       "      <td>2022-09-09</td>\n",
       "      <td>2022-09-10</td>\n",
       "      <td>LE CANH NGUYEN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>ca994e4d-5eba-48de-985d-c7ae52c4e630</td>\n",
       "      <td>909978671</td>\n",
       "      <td>1.570407e+13</td>\n",
       "      <td>2. New HDB acc</td>\n",
       "      <td>in-app banking</td>\n",
       "      <td>2022-09-08</td>\n",
       "      <td>2022-09-08</td>\n",
       "      <td>TRAN NGOC MINH TUAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>d23a42c7-b8ab-48c2-87fa-44f1fc572913</td>\n",
       "      <td>969701624</td>\n",
       "      <td>6.870407e+13</td>\n",
       "      <td>2. New HDB acc</td>\n",
       "      <td>in-app banking</td>\n",
       "      <td>2022-09-09</td>\n",
       "      <td>2022-09-09</td>\n",
       "      <td>NGUYEN KY PHONG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>e41b91cc-392f-49f5-bdff-705839c86dee</td>\n",
       "      <td>907935586</td>\n",
       "      <td>9.999910e+14</td>\n",
       "      <td>2. New HDB acc</td>\n",
       "      <td>in-app banking</td>\n",
       "      <td>2022-09-10</td>\n",
       "      <td>2022-09-10</td>\n",
       "      <td>NGUYEN NGOC MINH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>ea3bea7e-b776-4e04-a0ee-ce865e3d669d</td>\n",
       "      <td>364763244</td>\n",
       "      <td>9.999904e+14</td>\n",
       "      <td>2. New HDB acc</td>\n",
       "      <td>in-app banking</td>\n",
       "      <td>2022-09-09</td>\n",
       "      <td>2022-09-09</td>\n",
       "      <td>TRAN THI NHA LINH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>fe868696-646b-47d3-9df4-1a3b279ac14f</td>\n",
       "      <td>909256505</td>\n",
       "      <td>6.870407e+13</td>\n",
       "      <td>2. New HDB acc</td>\n",
       "      <td>in-app banking</td>\n",
       "      <td>2022-09-08</td>\n",
       "      <td>2022-09-08</td>\n",
       "      <td>NGUYEN THI THANH TRUC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>6dc1a74b-e068-46b7-a25c-c8f7c907bf96</td>\n",
       "      <td>968403223</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3. Dropoff Jul-Aug + Noti</td>\n",
       "      <td>cash</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>b995ac39-a14a-4c24-b109-656cbd33ddcf</td>\n",
       "      <td>336907106</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3. Dropoff Jul-Aug + Noti</td>\n",
       "      <td>cash</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>be87de6d-7f60-48d3-af66-fdbb15c2bb65</td>\n",
       "      <td>938038790</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3. Dropoff Jul-Aug + Noti</td>\n",
       "      <td>cash</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 user_id  phone_number  account_number  \\\n",
       "0   060a8e05-2ff3-4c9e-bf84-3c21d349531e     947845900    2.637041e+14   \n",
       "1   108882e7-7fc8-459f-ab04-1272736cd15f     888235816    6.870407e+13   \n",
       "2   12233148-c010-4e4f-a99f-69204a0a9b83     987722954    6.870407e+13   \n",
       "3   1e6acde9-5d69-42c1-b538-37f49ffd094a     374351851    9.999904e+14   \n",
       "4   20ddfb21-1665-4fc9-9a30-db6c1c3c9dfb     868077077    1.117041e+14   \n",
       "5   4668a071-f22e-41dd-82ca-af5ecf493652     919238636    8.270407e+13   \n",
       "6   5a6132ee-acc8-4698-ac2d-d8ceb4e59ab4     917220226    1.237041e+14   \n",
       "7   5a9b0c42-2d97-43f3-b0ac-46def015756a     947128158    6.870407e+13   \n",
       "8   5b66d9c7-6bc6-4a31-9bac-5f19df99ccf0     983215799    6.870407e+13   \n",
       "9   8cc45d67-6405-458d-8b86-76834f9fdb64     909733028    8.970407e+13   \n",
       "10  b056bc52-3719-40ec-bf0e-9127fb76bb70     932080184    8.970407e+13   \n",
       "11  bd6c3d13-f5fb-4f38-a770-8090d54f8e84     938638169    1.470407e+13   \n",
       "12  cc2febc2-7be7-4151-9834-8d478411bf65     355097069    2.287041e+14   \n",
       "13  d0eb4b72-657b-48ba-91cc-52855febe7bf     876667373    6.870407e+13   \n",
       "14  ed0cbf71-1f1e-4706-b011-441c3df0de2e     345280737    1.047041e+14   \n",
       "15  1dcc548b-a33d-43dd-9e1f-55f189ceec34     963099780    6.870407e+13   \n",
       "16  289bf7c8-42f0-4d9c-9268-ad323fa2a52e     904020583    6.870407e+13   \n",
       "17  7ce9ee07-b59b-47bd-b476-250ade393703     392219121    6.870407e+13   \n",
       "18  a998cc49-3224-4be8-89eb-df0d498f3767     974286156    9.999910e+14   \n",
       "19  b1fe84ee-c73d-4a17-9d60-3ab99a07479c     334074063    6.870407e+13   \n",
       "20  ca994e4d-5eba-48de-985d-c7ae52c4e630     909978671    1.570407e+13   \n",
       "21  d23a42c7-b8ab-48c2-87fa-44f1fc572913     969701624    6.870407e+13   \n",
       "22  e41b91cc-392f-49f5-bdff-705839c86dee     907935586    9.999910e+14   \n",
       "23  ea3bea7e-b776-4e04-a0ee-ce865e3d669d     364763244    9.999904e+14   \n",
       "24  fe868696-646b-47d3-9df4-1a3b279ac14f     909256505    6.870407e+13   \n",
       "25  6dc1a74b-e068-46b7-a25c-c8f7c907bf96     968403223             NaN   \n",
       "26  b995ac39-a14a-4c24-b109-656cbd33ddcf     336907106             NaN   \n",
       "27  be87de6d-7f60-48d3-af66-fdbb15c2bb65     938038790             NaN   \n",
       "\n",
       "                     campagin  payment_method success_ekyc pro_purchase  \\\n",
       "0         1. Existing HDB acc  in-app banking   2022-06-13   2022-09-08   \n",
       "1         1. Existing HDB acc  in-app banking   2022-08-26   2022-09-08   \n",
       "2         1. Existing HDB acc  in-app banking   2022-06-14   2022-09-10   \n",
       "3         1. Existing HDB acc       pro_renew   2022-08-09   2022-09-08   \n",
       "4         1. Existing HDB acc  in-app banking   2022-08-20   2022-09-10   \n",
       "5         1. Existing HDB acc  in-app banking   2022-07-13   2022-09-08   \n",
       "6         1. Existing HDB acc  in-app banking   2022-06-24   2022-09-08   \n",
       "7         1. Existing HDB acc  in-app banking   2022-08-04   2022-09-08   \n",
       "8         1. Existing HDB acc  in-app banking   2022-09-07   2022-09-08   \n",
       "9         1. Existing HDB acc  in-app banking   2022-06-28   2022-09-10   \n",
       "10        1. Existing HDB acc  in-app banking   2022-07-01   2022-09-09   \n",
       "11        1. Existing HDB acc            cash   2022-04-29   2022-09-08   \n",
       "12        1. Existing HDB acc  in-app banking   2022-08-17   2022-09-09   \n",
       "13        1. Existing HDB acc  in-app banking   2022-08-16   2022-09-10   \n",
       "14        1. Existing HDB acc  in-app banking   2022-07-06   2022-09-08   \n",
       "15             2. New HDB acc  in-app banking   2022-09-09   2022-09-09   \n",
       "16             2. New HDB acc  in-app banking   2022-09-08   2022-09-09   \n",
       "17             2. New HDB acc  in-app banking   2022-09-09   2022-09-09   \n",
       "18             2. New HDB acc  in-app banking   2022-09-09   2022-09-09   \n",
       "19             2. New HDB acc  in-app banking   2022-09-09   2022-09-10   \n",
       "20             2. New HDB acc  in-app banking   2022-09-08   2022-09-08   \n",
       "21             2. New HDB acc  in-app banking   2022-09-09   2022-09-09   \n",
       "22             2. New HDB acc  in-app banking   2022-09-10   2022-09-10   \n",
       "23             2. New HDB acc  in-app banking   2022-09-09   2022-09-09   \n",
       "24             2. New HDB acc  in-app banking   2022-09-08   2022-09-08   \n",
       "25  3. Dropoff Jul-Aug + Noti            cash          NaN          NaN   \n",
       "26  3. Dropoff Jul-Aug + Noti            cash          NaN          NaN   \n",
       "27  3. Dropoff Jul-Aug + Noti            cash          NaN          NaN   \n",
       "\n",
       "              accountName  \n",
       "0            LE HONG NGOC  \n",
       "1              LE MY HANH  \n",
       "2           BUI VAN GIANG  \n",
       "3         HOANG VAN THIEN  \n",
       "4          BUI HONG QUANG  \n",
       "5          LUU PHUC THANH  \n",
       "6            TO THUY OANH  \n",
       "7           LE DUY PHUONG  \n",
       "8           PHAN VAN VIET  \n",
       "9           DAO XUAN TRUC  \n",
       "10            VU THI THUY  \n",
       "11     TRAN THI HONG DIEU  \n",
       "12           DINH VAN NHO  \n",
       "13           VO AN H KHOA  \n",
       "14        NGUYEN VAN TOAN  \n",
       "15         DINH THI LUYEN  \n",
       "16    LUONG THI ANH TUYET  \n",
       "17        NGUYEN THIEN AN  \n",
       "18        NGUYEN VAN TUNG  \n",
       "19         LE CANH NGUYEN  \n",
       "20    TRAN NGOC MINH TUAN  \n",
       "21        NGUYEN KY PHONG  \n",
       "22       NGUYEN NGOC MINH  \n",
       "23      TRAN THI NHA LINH  \n",
       "24  NGUYEN THI THANH TRUC  \n",
       "25                    NaN  \n",
       "26                    NaN  \n",
       "27                    NaN  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "#Create PySpark DataFrame from Pandas\n",
    "df=spark.read.format(\"csv\").option(\"header\",\"true\").load('/opt/workspace/data/temp.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------+---------------+-------------------+--------------+------------+------------+-------------------+\n",
      "|             user_id|phone_number| account_number|           campagin|payment_method|success_ekyc|pro_purchase|        accountName|\n",
      "+--------------------+------------+---------------+-------------------+--------------+------------+------------+-------------------+\n",
      "|060a8e05-2ff3-4c9...|   947845900|263704070001341|1. Existing HDB acc|in-app banking|  2022-06-13|  2022-09-08|       LE HONG NGOC|\n",
      "|108882e7-7fc8-459...|   888235816|068704070184503|1. Existing HDB acc|in-app banking|  2022-08-26|  2022-09-08|         LE MY HANH|\n",
      "|12233148-c010-4e4...|   987722954|068704070171437|1. Existing HDB acc|in-app banking|  2022-06-14|  2022-09-10|      BUI VAN GIANG|\n",
      "|1e6acde9-5d69-42c...|   374351851|999990374351851|1. Existing HDB acc|     pro_renew|  2022-08-09|  2022-09-08|    HOANG VAN THIEN|\n",
      "|20ddfb21-1665-4fc...|   868077077|111704070028365|1. Existing HDB acc|in-app banking|  2022-08-20|  2022-09-10|     BUI HONG QUANG|\n",
      "|4668a071-f22e-41d...|   919238636|082704070005545|1. Existing HDB acc|in-app banking|  2022-07-13|  2022-09-08|     LUU PHUC THANH|\n",
      "|5a6132ee-acc8-469...|   917220226|123704070015811|1. Existing HDB acc|in-app banking|  2022-06-24|  2022-09-08|       TO THUY OANH|\n",
      "|5a9b0c42-2d97-43f...|   947128158|068704070173879|1. Existing HDB acc|in-app banking|  2022-08-04|  2022-09-08|      LE DUY PHUONG|\n",
      "|5b66d9c7-6bc6-4a3...|   983215799|068704070187146|1. Existing HDB acc|in-app banking|  2022-09-07|  2022-09-08|      PHAN VAN VIET|\n",
      "|8cc45d67-6405-458...|   909733028|089704070006933|1. Existing HDB acc|in-app banking|  2022-06-28|  2022-09-10|      DAO XUAN TRUC|\n",
      "|b056bc52-3719-40e...|   932080184|089704070006871|1. Existing HDB acc|in-app banking|  2022-07-01|  2022-09-09|        VU THI THUY|\n",
      "|bd6c3d13-f5fb-4f3...|   938638169|014704070007774|1. Existing HDB acc|          cash|  2022-04-29|  2022-09-08| TRAN THI HONG DIEU|\n",
      "|cc2febc2-7be7-415...|   355097069|228704070011511|1. Existing HDB acc|in-app banking|  2022-08-17|  2022-09-09|       DINH VAN NHO|\n",
      "|d0eb4b72-657b-48b...|   876667373|068704070179071|1. Existing HDB acc|in-app banking|  2022-08-16|  2022-09-10|       VO AN H KHOA|\n",
      "|ed0cbf71-1f1e-470...|   345280737|104704070006938|1. Existing HDB acc|in-app banking|  2022-07-06|  2022-09-08|    NGUYEN VAN TOAN|\n",
      "|1dcc548b-a33d-43d...|   963099780|068704070187303|     2. New HDB acc|in-app banking|  2022-09-09|  2022-09-09|     DINH THI LUYEN|\n",
      "|289bf7c8-42f0-4d9...|   904020583|068704070187279|     2. New HDB acc|in-app banking|  2022-09-08|  2022-09-09|LUONG THI ANH TUYET|\n",
      "|7ce9ee07-b59b-47b...|   392219121|068704070187290|     2. New HDB acc|in-app banking|  2022-09-09|  2022-09-09|    NGUYEN THIEN AN|\n",
      "|a998cc49-3224-4be...|   974286156|999990974286156|     2. New HDB acc|in-app banking|  2022-09-09|  2022-09-09|    NGUYEN VAN TUNG|\n",
      "|b1fe84ee-c73d-4a1...|   334074063|068704070187306|     2. New HDB acc|in-app banking|  2022-09-09|  2022-09-10|     LE CANH NGUYEN|\n",
      "+--------------------+------------+---------------+-------------------+--------------+------------+------------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe stored in Hadoop.\n"
     ]
    }
   ],
   "source": [
    "df.write.option(\"header\",True) \\\n",
    "        .partitionBy(\"success_ekyc\") \\\n",
    "        .mode(\"overwrite\") \\\n",
    "        .parquet(\"hdfs://namenode/sales\")\n",
    "print(\"Dataframe stored in Hadoop.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling o50.parquet.\n: java.net.ConnectException: Call From 0c2f2d771445/172.18.0.3 to namenode:8020 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused\n\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n\tat org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:831)\n\tat org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:755)\n\tat org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1515)\n\tat org.apache.hadoop.ipc.Client.call(Client.java:1457)\n\tat org.apache.hadoop.ipc.Client.call(Client.java:1367)\n\tat org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)\n\tat org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)\n\tat com.sun.proxy.$Proxy25.getFileInfo(Unknown Source)\n\tat org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.getFileInfo(ClientNamenodeProtocolTranslatorPB.java:903)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)\n\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)\n\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)\n\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)\n\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)\n\tat com.sun.proxy.$Proxy26.getFileInfo(Unknown Source)\n\tat org.apache.hadoop.hdfs.DFSClient.getFileInfo(DFSClient.java:1665)\n\tat org.apache.hadoop.hdfs.DistributedFileSystem$29.doCall(DistributedFileSystem.java:1582)\n\tat org.apache.hadoop.hdfs.DistributedFileSystem$29.doCall(DistributedFileSystem.java:1579)\n\tat org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)\n\tat org.apache.hadoop.hdfs.DistributedFileSystem.getFileStatus(DistributedFileSystem.java:1594)\n\tat org.apache.hadoop.fs.FileSystem.exists(FileSystem.java:1683)\n\tat org.apache.spark.sql.execution.datasources.InsertIntoHadoopFsRelationCommand.run(InsertIntoHadoopFsRelationCommand.scala:119)\n\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.sideEffectResult$lzycompute(commands.scala:108)\n\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.sideEffectResult(commands.scala:106)\n\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.doExecute(commands.scala:131)\n\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$execute$1(SparkPlan.scala:180)\n\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$executeQuery$1(SparkPlan.scala:218)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:215)\n\tat org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:176)\n\tat org.apache.spark.sql.execution.QueryExecution.toRdd$lzycompute(QueryExecution.scala:132)\n\tat org.apache.spark.sql.execution.QueryExecution.toRdd(QueryExecution.scala:131)\n\tat org.apache.spark.sql.DataFrameWriter.$anonfun$runCommand$1(DataFrameWriter.scala:989)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n\tat org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:989)\n\tat org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:438)\n\tat org.apache.spark.sql.DataFrameWriter.saveInternal(DataFrameWriter.scala:415)\n\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:293)\n\tat org.apache.spark.sql.DataFrameWriter.parquet(DataFrameWriter.scala:874)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.lang.Thread.run(Thread.java:750)\nCaused by: java.net.ConnectException: Connection refused\n\tat sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)\n\tat sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:716)\n\tat org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)\n\tat org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)\n\tat org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:690)\n\tat org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:794)\n\tat org.apache.hadoop.ipc.Client$Connection.access$3700(Client.java:411)\n\tat org.apache.hadoop.ipc.Client.getConnection(Client.java:1572)\n\tat org.apache.hadoop.ipc.Client.call(Client.java:1403)\n\t... 54 more\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moption\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mheader\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m\\\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpartitionBy\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msuccess_ekyc\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m\\\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43moverwrite\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m\\\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparquet\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mhdfs://namenode/test\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataframe stored in Hadoop.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~opt/bitnami/spark/python/pyspark/sql/readwriter.py:1250\u001b[0m, in \u001b[0;36mDataFrameWriter.parquet\u001b[0;34m(self, path, mode, partitionBy, compression)\u001b[0m\n\u001b[1;32m   1248\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpartitionBy(partitionBy)\n\u001b[1;32m   1249\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_opts(compression\u001b[38;5;241m=\u001b[39mcompression)\n\u001b[0;32m-> 1250\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jwrite\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparquet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~opt/bitnami/python/lib/python3.8/site-packages/py4j/java_gateway.py:1304\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1298\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1299\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1300\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1301\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1303\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1304\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1305\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1307\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[1;32m   1308\u001b[0m     temp_arg\u001b[38;5;241m.\u001b[39m_detach()\n",
      "File \u001b[0;32m~opt/bitnami/spark/python/pyspark/sql/utils.py:111\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdeco\u001b[39m(\u001b[38;5;241m*\u001b[39ma, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw):\n\u001b[1;32m    110\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 111\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    112\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m py4j\u001b[38;5;241m.\u001b[39mprotocol\u001b[38;5;241m.\u001b[39mPy4JJavaError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    113\u001b[0m         converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n",
      "File \u001b[0;32m~opt/bitnami/python/lib/python3.8/site-packages/py4j/protocol.py:326\u001b[0m, in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    324\u001b[0m value \u001b[38;5;241m=\u001b[39m OUTPUT_CONVERTER[\u001b[38;5;28mtype\u001b[39m](answer[\u001b[38;5;241m2\u001b[39m:], gateway_client)\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m answer[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m REFERENCE_TYPE:\n\u001b[0;32m--> 326\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JJavaError(\n\u001b[1;32m    327\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[1;32m    328\u001b[0m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name), value)\n\u001b[1;32m    329\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    330\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JError(\n\u001b[1;32m    331\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m. Trace:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{3}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[1;32m    332\u001b[0m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name, value))\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o50.parquet.\n: java.net.ConnectException: Call From 0c2f2d771445/172.18.0.3 to namenode:8020 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused\n\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n\tat org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:831)\n\tat org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:755)\n\tat org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1515)\n\tat org.apache.hadoop.ipc.Client.call(Client.java:1457)\n\tat org.apache.hadoop.ipc.Client.call(Client.java:1367)\n\tat org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)\n\tat org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)\n\tat com.sun.proxy.$Proxy25.getFileInfo(Unknown Source)\n\tat org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.getFileInfo(ClientNamenodeProtocolTranslatorPB.java:903)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)\n\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)\n\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)\n\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)\n\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)\n\tat com.sun.proxy.$Proxy26.getFileInfo(Unknown Source)\n\tat org.apache.hadoop.hdfs.DFSClient.getFileInfo(DFSClient.java:1665)\n\tat org.apache.hadoop.hdfs.DistributedFileSystem$29.doCall(DistributedFileSystem.java:1582)\n\tat org.apache.hadoop.hdfs.DistributedFileSystem$29.doCall(DistributedFileSystem.java:1579)\n\tat org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)\n\tat org.apache.hadoop.hdfs.DistributedFileSystem.getFileStatus(DistributedFileSystem.java:1594)\n\tat org.apache.hadoop.fs.FileSystem.exists(FileSystem.java:1683)\n\tat org.apache.spark.sql.execution.datasources.InsertIntoHadoopFsRelationCommand.run(InsertIntoHadoopFsRelationCommand.scala:119)\n\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.sideEffectResult$lzycompute(commands.scala:108)\n\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.sideEffectResult(commands.scala:106)\n\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.doExecute(commands.scala:131)\n\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$execute$1(SparkPlan.scala:180)\n\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$executeQuery$1(SparkPlan.scala:218)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:215)\n\tat org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:176)\n\tat org.apache.spark.sql.execution.QueryExecution.toRdd$lzycompute(QueryExecution.scala:132)\n\tat org.apache.spark.sql.execution.QueryExecution.toRdd(QueryExecution.scala:131)\n\tat org.apache.spark.sql.DataFrameWriter.$anonfun$runCommand$1(DataFrameWriter.scala:989)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n\tat org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:989)\n\tat org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:438)\n\tat org.apache.spark.sql.DataFrameWriter.saveInternal(DataFrameWriter.scala:415)\n\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:293)\n\tat org.apache.spark.sql.DataFrameWriter.parquet(DataFrameWriter.scala:874)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.lang.Thread.run(Thread.java:750)\nCaused by: java.net.ConnectException: Connection refused\n\tat sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)\n\tat sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:716)\n\tat org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)\n\tat org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)\n\tat org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:690)\n\tat org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:794)\n\tat org.apache.hadoop.ipc.Client$Connection.access$3700(Client.java:411)\n\tat org.apache.hadoop.ipc.Client.getConnection(Client.java:1572)\n\tat org.apache.hadoop.ipc.Client.call(Client.java:1403)\n\t... 54 more\n"
     ]
    }
   ],
   "source": [
    "df.write.option(\"header\",True) \\\n",
    "        .partitionBy(\"success_ekyc\") \\\n",
    "        .mode(\"overwrite\") \\\n",
    "        .parquet(\"hdfs://namenode/test\")\n",
    "print(\"Dataframe stored in Hadoop.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe stored in Hadoop.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/09/01 04:18:08 ERROR StandaloneSchedulerBackend: Application has been killed. Reason: Master removed our application: KILLED\n",
      "23/09/01 04:18:08 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exiting due to error from cluster scheduler: Master removed our application: KILLED\n",
      "\tat org.apache.spark.scheduler.TaskSchedulerImpl.error(TaskSchedulerImpl.scala:873)\n",
      "\tat org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend.dead(StandaloneSchedulerBackend.scala:154)\n",
      "\tat org.apache.spark.deploy.client.StandaloneAppClient$ClientEndpoint.markDead(StandaloneAppClient.scala:262)\n",
      "\tat org.apache.spark.deploy.client.StandaloneAppClient$ClientEndpoint$$anonfun$receive$1.applyOrElse(StandaloneAppClient.scala:169)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:115)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "23/09/01 04:18:08 ERROR TaskSchedulerImpl: Lost executor 1 on 172.18.0.5: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.\n",
      "23/09/01 04:18:08 ERROR TaskSchedulerImpl: Lost executor 0 on 172.18.0.7: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.\n"
     ]
    }
   ],
   "source": [
    "df.write.option(\"header\",True) \\\n",
    "        .partitionBy(\"success_ekyc\") \\\n",
    "        .mode(\"overwrite\") \\\n",
    "        .parquet(\"hdfs://172.18.0.10:8020/test\")\n",
    "print(\"Dataframe stored in Hadoop.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "2f155fbeb9494e5ce992090b8427abe3542dae7719d8ea0d05cb0b78608edd18"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
